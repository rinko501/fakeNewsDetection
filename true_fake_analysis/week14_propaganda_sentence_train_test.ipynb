{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding:utf-8 -*-\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import csv\n",
    "from scipy.stats import chi2_contingency\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,f1_score,roc_auc_score,roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_propaganda_task2():\n",
    "    '''\n",
    "    output:[[sentence, label]]\n",
    "    '''\n",
    "    global_sentence_label = list()\n",
    "    \n",
    "    tesk_2_3_path = '../other_dict/tasks-2-3/train/'\n",
    "    target_data_2_dirs = os.listdir(tesk_2_3_path)\n",
    "    article_name_set = set()\n",
    "    for file_name in target_data_2_dirs:\n",
    "        article_name_set.add(file_name.split(\".\")[0])\n",
    "    for index in list(article_name_set):\n",
    "        text_name = tesk_2_3_path + index + '.txt'\n",
    "        try:\n",
    "            text = open(text_name, encoding='utf-8', mode='r')\n",
    "        except:\n",
    "            print('No such file or directory: ', text_name)\n",
    "            continue\n",
    "        label_name = tesk_2_3_path + index + '.task2.labels'\n",
    "        try:\n",
    "            label = open(label_name, encoding='utf-8', mode='r')\n",
    "        except:\n",
    "            print('No such file or directory: ', label_name)\n",
    "            continue\n",
    "        text = text.readlines()\n",
    "        sentence_list = []\n",
    "        for sentence in text:\n",
    "            sentence_list.append(sentence)\n",
    "        label = label.readlines()\n",
    "        label_list = []\n",
    "        for line in label:\n",
    "            label_list.append(line)\n",
    "        assert len(label_list)==len(sentence_list),\"text name %s, len of text %d, \\\n",
    "                len of label %d\"%(text_name, len(sentence_list), len(label_list))\n",
    "        for index,sentence in enumerate(sentence_list):\n",
    "            if \"\\tnon-propaganda\" in label_list[index] and sentence.strip()!=\"\":\n",
    "                global_sentence_label.append([sentence.strip(),0])\n",
    "            elif \"\\tpropaganda\" in label_list[index] and sentence.strip()!=\"\":\n",
    "                global_sentence_label.append([sentence.strip(),1])\n",
    "            else:\n",
    "                continue\n",
    "    return global_sentence_label\n",
    "# load data\n",
    "global_sentence_label = load_propaganda_task2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pos_word_dict = dict()\n",
    "neg_word_dict = dict()\n",
    "pos_num = 0\n",
    "neg_num = 0\n",
    "for ele in global_sentence_label:\n",
    "    if ele[1]==1:\n",
    "        pos_num += 1\n",
    "        word_list = set(ele[0].lower().split(\" \"))\n",
    "        for word in word_list:\n",
    "            if word in pos_word_dict:\n",
    "                pos_word_dict[word] += 1\n",
    "            else:\n",
    "                pos_word_dict[word] = 1\n",
    "    else:\n",
    "        neg_num += 1\n",
    "        word_list = set(ele[0].split(\" \"))\n",
    "        for word in word_list:\n",
    "            if word in neg_word_dict:\n",
    "                neg_word_dict[word] += 1\n",
    "            else:\n",
    "                neg_word_dict[word] = 1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_word_set = set(pos_word_dict.keys())\n",
    "neg_word_set = set(neg_word_dict.keys())\n",
    "all_word_set = pos_word_set.union(neg_word_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pos_significant_word_set = set()\n",
    "neg_significant_word_set = set()\n",
    "for word in all_word_set:\n",
    "    if word in pos_word_dict.keys():\n",
    "        word_in_pos = pos_word_dict[word]\n",
    "    else:\n",
    "        word_in_pos = 0\n",
    "    if word in neg_word_dict.keys():\n",
    "        word_in_neg = neg_word_dict[word]\n",
    "    else:\n",
    "        word_in_neg = 0\n",
    "        \n",
    "    if word_in_pos + word_in_neg > 10:\n",
    "        word_not_in_pos = pos_num - word_in_pos\n",
    "        word_not_in_neg = neg_num - word_in_neg\n",
    "        g, p, dof, expctd = chi2_contingency(np.array([[word_in_pos, word_not_in_pos],[word_in_neg, word_not_in_neg]]))\n",
    "        if p < 0.05:\n",
    "            if word_in_pos > word_in_neg:\n",
    "                pos_significant_word_set.add(word)\n",
    "            else:\n",
    "                neg_significant_word_set.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of pos significant words 491, num of neg significant word 792\n"
     ]
    }
   ],
   "source": [
    "print(\"num of pos significant words %d, num of neg significant word %d\"%(len(pos_significant_word_set), len(neg_significant_word_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get pos_nrc_emotion Data Begining ......\n",
      "len of pos nrm word dict is  113\n",
      "Get neg_nrc_emotion Data Begining ......\n",
      "len of neg nrm word dict is  62\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target_word_name='nrc_emotion'\n",
    "print(\"Get pos_\"+target_word_name+\" Data Begining ......\")\n",
    "nrc_word_dict = dict()\n",
    "nrc_word_set=set()\n",
    "if target_word_name == 'nrc_emotion':\n",
    "        target_data = open('../other_dict/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt', encoding='utf-8', mode='r')\n",
    "        target_data = target_data.readlines()\n",
    "        for line in target_data:\n",
    "            line = line.strip('\\n\\r').lower().split('\\t')\n",
    "            if len(line)==3 and line[2]== \"1\" and line[0] in pos_significant_word_set:\n",
    "                nrc_word_set.add(line[0])\n",
    "        for word in nrc_word_set:\n",
    "            nrc_word_dict[word] = 1            \n",
    "print(\"len of pos nrm word dict is \", len(nrc_word_dict))\n",
    "new_target_words_path = './result_fake_true_after_reduce_stopwords/true_' + target_word_name + '_words.csv'\n",
    "with open(new_target_words_path, \"w\") as new_key_words:\n",
    "    writer = csv.writer(new_key_words)\n",
    "    for key in nrc_word_dict.keys():\n",
    "        word = key\n",
    "        try:\n",
    "            word_weight = nrc_word_dict[word]\n",
    "        except:\n",
    "            word_weight = 'None'\n",
    "        writer.writerow([word, word_weight])\n",
    "\n",
    "target_word_name='nrc_emotion'\n",
    "print(\"Get neg_\"+target_word_name+\" Data Begining ......\")\n",
    "nrc_word_dict = dict()\n",
    "nrc_word_set=set()\n",
    "if target_word_name == 'nrc_emotion':\n",
    "        target_data = open('../other_dict/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt', encoding='utf-8', mode='r')\n",
    "        target_data = target_data.readlines()\n",
    "        for line in target_data:\n",
    "            line = line.strip('\\n\\r').lower().split('\\t')\n",
    "            if len(line)==3 and line[2]== \"1\" and line[0] in neg_significant_word_set:\n",
    "                nrc_word_set.add(line[0])\n",
    "        for word in nrc_word_set:\n",
    "            nrc_word_dict[word] = 1            \n",
    "print(\"len of neg nrm word dict is \", len(nrc_word_dict))\n",
    "new_target_words_path = './result_fake_true_after_reduce_stopwords/fake_' + target_word_name + '_words.csv'\n",
    "with open(new_target_words_path, \"w\") as new_key_words:\n",
    "    writer = csv.writer(new_key_words)\n",
    "    for key in nrc_word_dict.keys():\n",
    "        word = key\n",
    "        try:\n",
    "            word_weight = nrc_word_dict[word]\n",
    "        except:\n",
    "            word_weight = 'None'\n",
    "        writer.writerow([word, word_weight])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of sentence is 4032\n",
      "num of pos sentence is 1239\n",
      "num of neg sentence is 2793\n"
     ]
    }
   ],
   "source": [
    "global_test_sentence_label = list()\n",
    "sentence_test_list = []\n",
    "label_test_list = []\n",
    "with open('../other_dict/new_propaganda_test/task2test_rs.csv','r') as csvfile_test_test:\n",
    "    reader_test = csv.reader(csvfile_test_test)\n",
    "    for i,rows in enumerate(reader_test):\n",
    "        row_test = rows\n",
    "        text_test = row_test[3]\n",
    "        label =row_test[2]\n",
    "        if label==\"non-propaganda\":\n",
    "            global_test_sentence_label.append([text_test,0])\n",
    "        elif label==\"propaganda\":\n",
    "            global_test_sentence_label.append([text_test,1])\n",
    "        else:\n",
    "            continue\n",
    "# partition to positive/negative\n",
    "global_test_sentence_label_positive = [pair for pair in global_test_sentence_label if pair[1]==1]\n",
    "global_test_sentence_label_negative = [pair for pair in global_test_sentence_label if pair[1]==0]\n",
    "print(\"num of sentence is %d\"%(len(global_test_sentence_label)))\n",
    "print(\"num of pos sentence is %d\"%(len(global_test_sentence_label_positive)))\n",
    "print(\"num of neg sentence is %d\"%(len(global_test_sentence_label_negative)))\n",
    "test_dataset = global_test_sentence_label_negative[:]\n",
    "test_dataset.extend(global_test_sentence_label_positive[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of sentence is 14263\n",
      "num of pos sentence is 3938\n",
      "num of neg sentence is 3938\n"
     ]
    }
   ],
   "source": [
    "def load_propaganda_task2():\n",
    "    '''\n",
    "    output:[[sentence, label]]\n",
    "    '''\n",
    "    global_sentence_label = list()\n",
    "    \n",
    "    tesk_2_3_path = '../other_dict/tasks-2-3/train/'\n",
    "    target_data_2_dirs = os.listdir(tesk_2_3_path)\n",
    "    article_name_set = set()\n",
    "    for file_name in target_data_2_dirs:\n",
    "        article_name_set.add(file_name.split(\".\")[0])\n",
    "    for index in list(article_name_set):\n",
    "        text_name = tesk_2_3_path + index + '.txt'\n",
    "        try:\n",
    "            text = open(text_name, encoding='utf-8', mode='r')\n",
    "        except:\n",
    "            print('No such file or directory: ', text_name)\n",
    "            continue\n",
    "        label_name = tesk_2_3_path + index + '.task2.labels'\n",
    "        try:\n",
    "            label = open(label_name, encoding='utf-8', mode='r')\n",
    "        except:\n",
    "            print('No such file or directory: ', label_name)\n",
    "            continue\n",
    "        text = text.readlines()\n",
    "        sentence_list = []\n",
    "        for sentence in text:\n",
    "            sentence_list.append(sentence)\n",
    "        label = label.readlines()\n",
    "        label_list = []\n",
    "        for line in label:\n",
    "            label_list.append(line)\n",
    "        assert len(label_list)==len(sentence_list),\"text name %s, len of text %d, \\\n",
    "                len of label %d\"%(text_name, len(sentence_list), len(label_list))\n",
    "        for index,sentence in enumerate(sentence_list):\n",
    "            if \"\\tnon-propaganda\" in label_list[index] and sentence.strip()!=\"\":\n",
    "                global_sentence_label.append([sentence,0])\n",
    "            elif \"\\tpropaganda\" in label_list[index] and sentence.strip()!=\"\":\n",
    "                global_sentence_label.append([sentence,1])\n",
    "            else:\n",
    "                continue\n",
    "    return global_sentence_label\n",
    "# load data\n",
    "global_sentence_label = load_propaganda_task2()\n",
    "np.random.shuffle(global_sentence_label)\n",
    "# partition to positive/negative\n",
    "global_sentence_label_positive = [pair for pair in global_sentence_label if pair[1]==1]\n",
    "global_sentence_label_negative = [pair for pair in global_sentence_label if pair[1]==0][:3938]\n",
    "print(\"num of sentence is %d\"%(len(global_sentence_label)))\n",
    "print(\"num of pos sentence is %d\"%(len(global_sentence_label_positive)))\n",
    "print(\"num of neg sentence is %d\"%(len(global_sentence_label_negative)))\n",
    "train_dataset = global_sentence_label_negative[:]\n",
    "train_dataset.extend(global_sentence_label_positive[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_feature_matrix: 7876\n",
      "train_label: 7876\n"
     ]
    }
   ],
   "source": [
    "def load_dict(dict_path):\n",
    "    word_set = set()\n",
    "    dict_text = open(dict_path, encoding='utf-8', mode='r')\n",
    "    for line in dict_text:\n",
    "        if line.strip()!=\"\":\n",
    "            word =line.split(\",\")[0]\n",
    "            word_set.add(word)\n",
    "    return word_set\n",
    "def word_num_in_dict(sentence, word_set):\n",
    "    try:\n",
    "        word_list = sentence.strip().split(\" \")\n",
    "    except:\n",
    "        print(sentence)\n",
    "    word_num = 0\n",
    "    for word in word_list:\n",
    "        if word in word_set:\n",
    "            word_num += 1\n",
    "    return word_num\n",
    "def build_feature_matrix_and_label(dataset,dict_names,dict_path):\n",
    "    num_sample = len(dataset)\n",
    "    num_feature = len(dict_names)\n",
    "    feature_matrix = np.zeros((num_sample, num_feature))\n",
    "    label = np.zeros((num_sample,))\n",
    "    for i in range(num_sample):\n",
    "        for j in range(num_feature):\n",
    "            if 'propaganda' in dict_names[j]:\n",
    "                dict_path='./result_fake_true_week5/'\n",
    "            else:\n",
    "                dict_path=\"./result_fake_true_after_reduce_stopwords/\"\n",
    "            feature_matrix[i,j] = word_num_in_dict(dataset[i][0], load_dict(dict_path + dict_names[j] + \"_words.csv\"))\n",
    "            \n",
    "        label[i] = dataset[i][1]\n",
    "    return feature_matrix,label\n",
    "def build_feature_matrix_new_one_dict(dataset,dict_name,dict_path):\n",
    "    if 'propaganda' in dict_name:\n",
    "        dict_path='./result_fake_true_week5/'\n",
    "    else:\n",
    "        dict_path=\"./result_fake_true_after_reduce_stopwords/\"\n",
    "    word_list = list(load_dict(dict_path+dict_name+ \"_words.csv\"))\n",
    "    num_sample = len(dataset)\n",
    "    num_feature = len(word_list)\n",
    "    feature_matrix = np.zeros((num_sample, num_feature))\n",
    "    for i in range(len(dataset)):\n",
    "        for j,word in enumerate(word_list):\n",
    "            if word in dataset[i][0]:\n",
    "                feature_matrix[i][j]=1\n",
    "    return(feature_matrix)\n",
    "\n",
    "dict_names = ['fake_persuasive','fake_sentiment','fake_subjectivity','fake_technical','fake_all',\n",
    "              'true_persuasive','true_sentiment','true_subjectivity','true_technical','true_all']\n",
    "dict_path = \"./result_fake_true_after_reduce_stopwords/\"\n",
    "train_feature_matrix, train_label = build_feature_matrix_and_label(train_dataset, dict_names, dict_path)\n",
    "test_feature_matrix, test_label = build_feature_matrix_and_label(test_dataset, dict_names, dict_path)\n",
    "print('train_feature_matrix:',len(train_feature_matrix))\n",
    "print('train_label:',len(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_feature_matrix: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# one-hot\n",
    "for dict_name in dict_names:\n",
    "    train_feature_matrix=np.hstack((build_feature_matrix_new_one_dict(train_dataset,dict_name,dict_path),train_feature_matrix))\n",
    "    test_feature_matrix=np.hstack((build_feature_matrix_new_one_dict(test_dataset,dict_name,dict_path),test_feature_matrix))\n",
    "    \n",
    "print('train_feature_matrix:',train_feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (7876, 1260) (7876,) (4032, 1260) (4032,)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape\",train_feature_matrix.shape, train_label.shape, test_feature_matrix.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train================================\n",
      "The train accuracy score of rf is : 0.607796\n",
      "confusion matrix is  [[2927 2078]\n",
      " [1011 1860]]\n",
      " positive f1: 0.5463357321192539\n",
      " negative f1: 0.6545901822654591\n",
      "The AUC of GBDT: 0.65401\n",
      "test================================\n",
      "The test accuracy score of rf is : 0.649554\n",
      "confusion matrix is  [[2108  728]\n",
      " [ 685  511]]\n",
      " positive f1: 0.4197125256673511\n",
      " negative f1: 0.7489785041748092\n",
      "The AUC of GBDT: 0.62034\n"
     ]
    }
   ],
   "source": [
    "#gbdt, train\n",
    "gbdt = GradientBoostingClassifier(max_depth=4,\n",
    "                                  random_state=0,\n",
    "                                  min_samples_split=5,\n",
    "                                  learning_rate=0.01,\n",
    "                                  n_estimators=30,\n",
    "                                  subsample=0.8)\n",
    "\n",
    "sample_weight = np.zeros(train_label.shape,np.float)\n",
    "sample_weight[train_label==1] = 1.0 / np.sum(train_label==1)\n",
    "sample_weight[train_label==0] = 1.0 / np.sum(train_label==0)\n",
    "rf = gbdt.fit(train_feature_matrix, train_label, sample_weight)\n",
    "\n",
    "print(\"train================================\")\n",
    "\n",
    "val_score_rbf = gbdt.score(train_feature_matrix, train_label)#val_score_rbf = gbdt.score(x, y)\n",
    "print(\"The train accuracy score of rf is : %f\" % val_score_rbf)\n",
    "predict_label = gbdt.predict(train_feature_matrix)\n",
    "prob_y = gbdt.predict_proba(train_feature_matrix)[:,1]\n",
    "cm = confusion_matrix(predict_label,train_label)\n",
    "print(\"confusion matrix is \", cm)\n",
    "#plot_confusion_matrix(cm, \"GBDT Confusion Matrix\")\n",
    "print(\" positive f1:\",f1_score(train_label,predict_label,pos_label=True))\n",
    "print(\" negative f1:\",f1_score(train_label,predict_label,pos_label=False))\n",
    "#print('test_feature_matrix:',test_feature_matrix)\n",
    "gbdt_auc = roc_auc_score(train_label, prob_y)\n",
    "print('The AUC of GBDT: %.5f' % gbdt_auc)\n",
    "\n",
    "print(\"test================================\")\n",
    "test_score_rbf = gbdt.score(test_feature_matrix, test_label)#test_score_rbf = gbdt.score(test_x, test_y)\n",
    "print(\"The test accuracy score of rf is : %f\" % test_score_rbf)\n",
    "predict_label = gbdt.predict(test_feature_matrix)\n",
    "prob_y = gbdt.predict_proba(test_feature_matrix)[:,1]\n",
    "cm = confusion_matrix(predict_label,test_label)\n",
    "print(\"confusion matrix is \", cm)\n",
    "#plot_confusion_matrix(cm, \"GBDT Confusion Matrix\")\n",
    "\n",
    "\n",
    "print(\" positive f1:\",f1_score(test_label,predict_label,pos_label=True))\n",
    "print(\" negative f1:\",f1_score(test_label,predict_label,pos_label=False))\n",
    "\n",
    "#print('test_feature_matrix:',test_feature_matrix)\n",
    "gbdt_auc = roc_auc_score(test_label, prob_y)\n",
    "print('The AUC of GBDT: %.5f' % gbdt_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
