{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import csv\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import xlrd\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import  metrics\n",
    "import random\n",
    "random.seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Fake_Data = []\n",
    "Train_True_Data = []\n",
    "Test_Fake_Data = []\n",
    "Test_True_Data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"./data/Fake_train\")\n",
    "for line in f.readlines():\n",
    "    Train_Fake_Data.append(line)\n",
    "f.close()\n",
    "\n",
    "f = open(\"./data/True_train\")\n",
    "for line in f.readlines():\n",
    "    Train_True_Data.append(line)\n",
    "f.close()\n",
    "\n",
    "f = open(\"./data/Fake_test\")\n",
    "for line in f.readlines():\n",
    "    Test_Fake_Data.append(line)\n",
    "f.close()\n",
    "\n",
    "f = open(\"./data/True_test\")\n",
    "for line in f.readlines():\n",
    "    Test_True_Data.append(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(True_data=None, Fake_data=None):\n",
    "    features_word = ['all', 'propaganda', 'persuasive','sentiment', 'subjectivity', 'technical']\n",
    "    all_feature_words_list = []\n",
    "    for i, word in enumerate(features_word):\n",
    "        true_path = './result_fake_true_after_reduce_stopwords/' + 'true_' + word + '_words.csv'\n",
    "        fake_path = './result_fake_true_after_reduce_stopwords/' + 'fake_' + word + '_words.csv'\n",
    "        true_words = open(true_path, encoding='utf-8', mode='r')\n",
    "        true_words_list = []\n",
    "        true_words = true_words.readlines()\n",
    "        for line in true_words:\n",
    "            line = line.strip('\\n\\r').split(',')\n",
    "            # print(line[0])\n",
    "            true_words_list.append(line[0])\n",
    "        all_feature_words_list.append(true_words_list)\n",
    "\n",
    "        fake_words = open(fake_path, encoding='utf-8', mode='r')\n",
    "        fake_words_list = []\n",
    "        fake_words = fake_words.readlines()\n",
    "        for line in fake_words:\n",
    "            line = line.strip('\\n\\r').split(',')\n",
    "            fake_words_list.append(line[0])\n",
    "            # print(line[0])\n",
    "        all_feature_words_list.append(fake_words_list)\n",
    "\n",
    "    print(len(all_feature_words_list))\n",
    "\n",
    "    all_data = []\n",
    "    for line in True_data[:]:\n",
    "        one_data = [0, ]\n",
    "        line = line.split(' ')\n",
    "        for feature in all_feature_words_list:\n",
    "            num = 0\n",
    "            for word in line:\n",
    "                if word in feature:\n",
    "                    num += 1\n",
    "            one_data.append(num)\n",
    "        # print(one_data)\n",
    "        all_data.append(one_data)\n",
    "\n",
    "    for line in Fake_data[:]:\n",
    "        one_data = [1, ]\n",
    "        line = line.split(' ')\n",
    "        for feature in all_feature_words_list:\n",
    "            num = 0\n",
    "            for word in line:\n",
    "                if word in feature:\n",
    "                    num += 1\n",
    "            one_data.append(num)\n",
    "        all_data.append(one_data)\n",
    "    print(all_data[:3])\n",
    "    '''\n",
    "    [0, 2, 0, 16, 5, 0, 0, 2, 0, 1, 0]\n",
    "    [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "    [1, 1, 0, 3, 0, 1, 0, 2, 0, 0, 0]\n",
    "    [1, 1, 0, 3, 1, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "[[0, 10, 0, 6, 0, 1, 0, 0, 0, 2, 0, 1, 0], [0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 6, 0, 7, 0, 2, 0, 0, 0, 1, 0, 2, 0]]\n",
      "12\n",
      "[[0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 15, 14, 7, 13, 1, 0, 0, 0, 3, 1, 2, 0], [0, 11, 5, 20, 4, 0, 2, 2, 2, 4, 3, 5, 0]]\n"
     ]
    }
   ],
   "source": [
    "train_data = get_feature(Train_True_Data, Train_Fake_Data)\n",
    "test_data = get_feature(Test_True_Data, Test_Fake_Data)\n",
    "\n",
    "random.shuffle(train_data)\n",
    "random.shuffle(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(train_data) \n",
    "# print(data)\n",
    "x = data[:, 1:]  \n",
    "y = data[:, 0].astype(int)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.array(test_data)\n",
    "test_x = test_data[:, 1:]  \n",
    "test_y = test_data[:, 0].astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train data is 4814 and each of part(1/5) is 962 \n",
      "0 962\n",
      "The train accuracy score of GBDT is : 0.900208\n",
      "The test accuracy score of GBDT is : 0.764925\n",
      "f1: 0.6911764705882353\n",
      "precision: 0.7268041237113402\n",
      "recall: 0.6588785046728972\n",
      "962 1924\n",
      "The train accuracy score of GBDT is : 0.913721\n",
      "The test accuracy score of GBDT is : 0.744403\n",
      "f1: 0.6513994910941475\n",
      "precision: 0.7150837988826816\n",
      "recall: 0.5981308411214953\n",
      "1924 2886\n",
      "The train accuracy score of GBDT is : 0.887734\n",
      "The test accuracy score of GBDT is : 0.755597\n",
      "f1: 0.6614987080103358\n",
      "precision: 0.7398843930635838\n",
      "recall: 0.5981308411214953\n",
      "2886 3848\n",
      "The train accuracy score of GBDT is : 0.901247\n",
      "The test accuracy score of GBDT is : 0.746269\n",
      "f1: 0.6650246305418719\n",
      "precision: 0.703125\n",
      "recall: 0.6308411214953271\n",
      "3848 4810\n",
      "The train accuracy score of GBDT is : 0.903326\n",
      "The test accuracy score of GBDT is : 0.727612\n",
      "f1: 0.6490384615384616\n",
      "precision: 0.6683168316831684\n",
      "recall: 0.6308411214953271\n",
      "avg of accuracy of five-fold cross validation is 0.747761\n",
      "avg of f1 of five-fold cross validation is 0.663628\n",
      "avg of precision of five-fold cross validation is 0.710643\n",
      "avg of recall of five-fold cross validation is 0.623364\n"
     ]
    }
   ],
   "source": [
    "#divide the train data into 5\n",
    "\n",
    "num_train = x.shape[0]\n",
    "num_each_part = num_train//5\n",
    "print(\"num of train data is %s and each of part(1/5) is %s \"%(num_train,num_each_part))\n",
    "test_accuracy_list = list()\n",
    "test_f1_list = list()\n",
    "test_precision_list=list()\n",
    "test_recall_list=list()\n",
    "for i in range(5):\n",
    "    print(num_each_part*i,num_each_part*(i+1))\n",
    "    train_x = x[num_each_part*i:num_each_part*(i+1)]\n",
    "    train_y = y[num_each_part*i:num_each_part*(i+1)]\n",
    "    gbdt = GradientBoostingClassifier(max_depth=6,\n",
    "                                      random_state=10,\n",
    "                                      min_samples_split=10,\n",
    "                                      learning_rate=0.01,\n",
    "                                      n_estimators=200,\n",
    "                                      subsample=0.85)\n",
    "    gbdt.fit(train_x,train_y)\n",
    "    train_score_rbf = gbdt.score(train_x, train_y)\n",
    "    print(\"The train accuracy score of GBDT is : %f\" % train_score_rbf)\n",
    "    test_score_rbf = gbdt.score(test_x, test_y)\n",
    "    print(\"The test accuracy score of GBDT is : %f\" % test_score_rbf)\n",
    "    predict_y = gbdt.predict(test_x)\n",
    "    prob_y = gbdt.predict_proba(test_x)[:,1]\n",
    "    from sklearn.metrics import confusion_matrix,f1_score\n",
    "    f1 = f1_score(test_y, predict_y, average='binary')\n",
    "    print(\"f1:\", f1 )\n",
    "    p = precision_score(test_y, predict_y, average='binary')\n",
    "    print(\"precision:\", p)\n",
    "    r = recall_score(test_y, predict_y,average='binary')\n",
    "    print(\"recall:\", r)\n",
    "\n",
    "    test_accuracy_list.append(test_score_rbf)\n",
    "    test_f1_list.append(f1)\n",
    "    test_precision_list.append(p)\n",
    "    test_recall_list.append(r)\n",
    "print(\"avg of accuracy of five-fold cross validation is %f\"%(np.mean(np.asarray(test_accuracy_list))))\n",
    "print(\"avg of f1 of five-fold cross validation is %f\"%(np.mean(np.asarray(test_f1_list))))\n",
    "print(\"avg of precision of five-fold cross validation is %f\"%(np.mean(np.asarray(test_precision_list))))\n",
    "print(\"avg of recall of five-fold cross validation is %f\"%(np.mean(np.asarray(test_recall_list))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('./extend_dict.json',\"r\")\n",
    "for line in f:\n",
    "    extend_dict=json.loads(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_extend(data):\n",
    "    res_data = []\n",
    "    for line in data:\n",
    "        new_line = []\n",
    "        for word in line.split(' '):\n",
    "            new_line.append(word)\n",
    "            if(word in extend_dict):\n",
    "                new_line.extend(extend_dict[word])\n",
    "        res_data.append(' '.join(new_line))\n",
    "    return res_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Fake_Data_ex = data_extend(Train_Fake_Data)\n",
    "Train_True_Data_ex = data_extend(Train_True_Data)\n",
    "Test_Fake_Data_ex = data_extend(Test_Fake_Data)\n",
    "Test_True_Data_ex = data_extend(Test_True_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_feature(True_data=None, Fake_data=None):\n",
    "    features_word = ['all_extend']\n",
    "    all_feature_words_list = []\n",
    "    for i, word in enumerate(features_word):\n",
    "        true_path = './result_fake_true_after_reduce_stopwords/' + 'true_' + word + '_words.csv'\n",
    "        fake_path = './result_fake_true_after_reduce_stopwords/' + 'fake_' + word + '_words.csv'\n",
    "        true_words = open(true_path, encoding='utf-8', mode='r')\n",
    "        true_words_list = []\n",
    "        true_words = true_words.readlines()\n",
    "        for line in true_words:\n",
    "            line = line.strip('\\n\\r').split(',')\n",
    "            # print(line[0])\n",
    "            true_words_list.append(line[0])\n",
    "        all_feature_words_list.append(true_words_list)\n",
    "\n",
    "        fake_words = open(fake_path, encoding='utf-8', mode='r')\n",
    "        fake_words_list = []\n",
    "        fake_words = fake_words.readlines()\n",
    "        for line in fake_words:\n",
    "            line = line.strip('\\n\\r').split(',')\n",
    "            fake_words_list.append(line[0])\n",
    "            # print(line[0])\n",
    "        all_feature_words_list.append(fake_words_list)\n",
    "\n",
    "    print(len(all_feature_words_list))\n",
    "\n",
    "    all_data = []\n",
    "    for line in True_data[:]:\n",
    "        one_data = [0, ]\n",
    "        line = line.split(' ')\n",
    "        for feature in all_feature_words_list:\n",
    "            num = 0\n",
    "            for word in line:\n",
    "                if word in feature:\n",
    "                    num += 1\n",
    "            one_data.append(num)\n",
    "        # print(one_data)\n",
    "        all_data.append(one_data)\n",
    "\n",
    "    for line in Fake_data[:]:\n",
    "        one_data = [1, ]\n",
    "        line = line.split(' ')\n",
    "        for feature in all_feature_words_list:\n",
    "            num = 0\n",
    "            for word in line:\n",
    "                if word in feature:\n",
    "                    num += 1\n",
    "            one_data.append(num)\n",
    "        all_data.append(one_data)\n",
    "    # print(all_data[:3])\n",
    "    '''\n",
    "    [0, 2, 0, 16, 5, 0, 0, 2, 0, 1, 0]\n",
    "    [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "    [1, 1, 0, 3, 0, 1, 0, 2, 0, 0, 0]\n",
    "    [1, 1, 0, 3, 1, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    " \n",
    "    '''\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "12\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "train_data = get_feature(Train_True_Data, Train_Fake_Data)\n",
    "test_data = get_feature(Test_True_Data, Test_Fake_Data)\n",
    "\n",
    "train_add = add_feature(Train_True_Data, Train_Fake_Data)\n",
    "test_add = add_feature(Test_True_Data, Test_Fake_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(data,add):\n",
    "    res = []\n",
    "    for i in range(len(data)):\n",
    "        data[i].extend(add[i][1:])\n",
    "        res.append(data[i])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = merge_data(train_data,train_add)\n",
    "test = merge_data(test_data,test_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(train_data) \n",
    "np.random.shuffle(data)\n",
    "# print(data)\n",
    "x = data[:, 1:]  \n",
    "y = data[:, 0].astype(int)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.array(test_data)\n",
    "test_x = test_data[:, 1:]  \n",
    "test_y = test_data[:, 0].astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train data is 4814 and each of part(1/5) is 962 \n",
      "0 962\n",
      "The train accuracy score of GBDT is : 0.920998\n",
      "The test accuracy score of GBDT is : 0.731343\n",
      "f1: 0.619047619047619\n",
      "precision: 0.7134146341463414\n",
      "recall: 0.5467289719626168\n",
      "962 1924\n",
      "The train accuracy score of GBDT is : 0.919958\n",
      "The test accuracy score of GBDT is : 0.738806\n",
      "f1: 0.6534653465346535\n",
      "precision: 0.6947368421052632\n",
      "recall: 0.616822429906542\n",
      "1924 2886\n",
      "The train accuracy score of GBDT is : 0.909563\n",
      "The test accuracy score of GBDT is : 0.748134\n",
      "f1: 0.6582278481012659\n",
      "precision: 0.7182320441988951\n",
      "recall: 0.6074766355140186\n",
      "2886 3848\n",
      "The train accuracy score of GBDT is : 0.917879\n",
      "The test accuracy score of GBDT is : 0.757463\n",
      "f1: 0.6632124352331605\n",
      "precision: 0.7441860465116279\n",
      "recall: 0.5981308411214953\n",
      "3848 4810\n",
      "The train accuracy score of GBDT is : 0.923077\n",
      "The test accuracy score of GBDT is : 0.725746\n",
      "f1: 0.6508313539192399\n",
      "precision: 0.6618357487922706\n",
      "recall: 0.6401869158878505\n",
      "avg of accuracy of five-fold cross validation is 0.740299\n",
      "avg of f1 of five-fold cross validation is 0.648957\n",
      "avg of precision of five-fold cross validation is 0.706481\n",
      "avg of recall of five-fold cross validation is 0.601869\n"
     ]
    }
   ],
   "source": [
    "num_train = x.shape[0]\n",
    "num_each_part = num_train//5\n",
    "print(\"num of train data is %s and each of part(1/5) is %s \"%(num_train,num_each_part))\n",
    "test_accuracy_list = list()\n",
    "test_f1_list = list()\n",
    "test_precision_list=list()\n",
    "test_recall_list=list()\n",
    "for i in range(5):\n",
    "    print(num_each_part*i,num_each_part*(i+1))\n",
    "    train_x = x[num_each_part*i:num_each_part*(i+1)]\n",
    "    train_y = y[num_each_part*i:num_each_part*(i+1)]\n",
    "    gbdt = GradientBoostingClassifier(max_depth=6,\n",
    "                                      random_state=10,\n",
    "                                      min_samples_split=10,\n",
    "                                      learning_rate=0.01,\n",
    "                                      n_estimators=200,\n",
    "                                      subsample=0.85)\n",
    "    gbdt.fit(train_x,train_y)\n",
    "    train_score_rbf = gbdt.score(train_x, train_y)\n",
    "    print(\"The train accuracy score of GBDT is : %f\" % train_score_rbf)\n",
    "    test_score_rbf = gbdt.score(test_x, test_y)\n",
    "    print(\"The test accuracy score of GBDT is : %f\" % test_score_rbf)\n",
    "    predict_y = gbdt.predict(test_x)\n",
    "    prob_y = gbdt.predict_proba(test_x)[:,1]\n",
    "    from sklearn.metrics import confusion_matrix,f1_score\n",
    "    f1 = f1_score(test_y, predict_y, average='binary')\n",
    "    print(\"f1:\", f1 )\n",
    "    p = precision_score(test_y, predict_y, average='binary')\n",
    "    print(\"precision:\", p)\n",
    "    r = recall_score(test_y, predict_y,average='binary')\n",
    "    print(\"recall:\", r)\n",
    "\n",
    "    test_accuracy_list.append(test_score_rbf)\n",
    "    test_f1_list.append(f1)\n",
    "    test_precision_list.append(p)\n",
    "    test_recall_list.append(r)\n",
    "print(\"avg of accuracy of five-fold cross validation is %f\"%(np.mean(np.asarray(test_accuracy_list))))\n",
    "print(\"avg of f1 of five-fold cross validation is %f\"%(np.mean(np.asarray(test_f1_list))))\n",
    "print(\"avg of precision of five-fold cross validation is %f\"%(np.mean(np.asarray(test_precision_list))))\n",
    "print(\"avg of recall of five-fold cross validation is %f\"%(np.mean(np.asarray(test_recall_list))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[:, 1:] \n",
    "y = data[:, 0].astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_data[:, 1:] \n",
    "test_y = test_data[:, 0].astype(int)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train data is 4814 and each of part(1/5) is 962 \n",
      "0 962\n",
      "The train accuracy score of GBDT is : 0.793139\n",
      "The test accuracy score of GBDT is : 0.755597\n",
      "f1: 0.6614987080103358\n",
      "precision: 0.7398843930635838\n",
      "recall: 0.5981308411214953\n",
      "962 1924\n",
      "The train accuracy score of GBDT is : 0.801455\n",
      "The test accuracy score of GBDT is : 0.746269\n",
      "f1: 0.643979057591623\n",
      "precision: 0.7321428571428571\n",
      "recall: 0.5747663551401869\n",
      "1924 2886\n",
      "The train accuracy score of GBDT is : 0.799376\n",
      "The test accuracy score of GBDT is : 0.722015\n",
      "f1: 0.6026666666666667\n",
      "precision: 0.7018633540372671\n",
      "recall: 0.5280373831775701\n",
      "2886 3848\n",
      "The train accuracy score of GBDT is : 0.788981\n",
      "The test accuracy score of GBDT is : 0.751866\n",
      "f1: 0.6336088154269972\n",
      "precision: 0.7718120805369127\n",
      "recall: 0.5373831775700935\n",
      "3848 4810\n",
      "The train accuracy score of GBDT is : 0.807692\n",
      "The test accuracy score of GBDT is : 0.751866\n",
      "f1: 0.6527415143603132\n",
      "precision: 0.7396449704142012\n",
      "recall: 0.5841121495327103\n",
      "avg of accuracy of five-fold cross validation is 0.745522\n",
      "avg of f1 of five-fold cross validation is 0.638899\n",
      "avg of precision of five-fold cross validation is 0.737070\n",
      "avg of recall of five-fold cross validation is 0.564486\n"
     ]
    }
   ],
   "source": [
    "num_train = x.shape[0]\n",
    "num_each_part = num_train//5\n",
    "print(\"num of train data is %s and each of part(1/5) is %s \"%(num_train,num_each_part))\n",
    "test_accuracy_list = list()\n",
    "test_f1_list = list()\n",
    "test_precision_list=list()\n",
    "test_recall_list=list()\n",
    "for i in range(5):\n",
    "    print(num_each_part*i,num_each_part*(i+1))\n",
    "    train_x = x[num_each_part*i:num_each_part*(i+1)]\n",
    "    train_y = y[num_each_part*i:num_each_part*(i+1)]\n",
    "    gbdt = LogisticRegression()\n",
    "    gbdt.fit(train_x,train_y)\n",
    "    train_score_rbf = gbdt.score(train_x, train_y)\n",
    "    print(\"The train accuracy score of GBDT is : %f\" % train_score_rbf)\n",
    "    test_score_rbf = gbdt.score(test_x, test_y)\n",
    "    print(\"The test accuracy score of GBDT is : %f\" % test_score_rbf)\n",
    "    predict_y = gbdt.predict(test_x)\n",
    "    prob_y = gbdt.predict_proba(test_x)[:,1]\n",
    "    from sklearn.metrics import confusion_matrix,f1_score\n",
    "    f1 = f1_score(test_y, predict_y, average='binary')\n",
    "    print(\"f1:\", f1 )\n",
    "    p = precision_score(test_y, predict_y, average='binary')\n",
    "    print(\"precision:\", p)\n",
    "    r = recall_score(test_y, predict_y,average='binary')\n",
    "    print(\"recall:\", r)\n",
    "\n",
    "    test_accuracy_list.append(test_score_rbf)\n",
    "    test_f1_list.append(f1)\n",
    "    test_precision_list.append(p)\n",
    "    test_recall_list.append(r)\n",
    "print(\"avg of accuracy of five-fold cross validation is %f\"%(np.mean(np.asarray(test_accuracy_list))))\n",
    "print(\"avg of f1 of five-fold cross validation is %f\"%(np.mean(np.asarray(test_f1_list))))\n",
    "print(\"avg of precision of five-fold cross validation is %f\"%(np.mean(np.asarray(test_precision_list))))\n",
    "print(\"avg of recall of five-fold cross validation is %f\"%(np.mean(np.asarray(test_recall_list))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR + standScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_std = scaler.transform(x)\n",
    "test_x_std = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train data is 4814 and each of part(1/5) is 962 \n",
      "0 962\n",
      "The train accuracy score of GBDT is : 0.773389\n",
      "The test accuracy score of GBDT is : 0.751866\n",
      "f1: 0.6395663956639566\n",
      "precision: 0.7612903225806451\n",
      "recall: 0.5514018691588785\n",
      "962 1924\n",
      "The train accuracy score of GBDT is : 0.792100\n",
      "The test accuracy score of GBDT is : 0.740672\n",
      "f1: 0.6170798898071626\n",
      "precision: 0.7516778523489933\n",
      "recall: 0.5233644859813084\n",
      "1924 2886\n",
      "The train accuracy score of GBDT is : 0.790021\n",
      "The test accuracy score of GBDT is : 0.727612\n",
      "f1: 0.6054054054054053\n",
      "precision: 0.717948717948718\n",
      "recall: 0.5233644859813084\n",
      "2886 3848\n",
      "The train accuracy score of GBDT is : 0.779626\n",
      "The test accuracy score of GBDT is : 0.731343\n",
      "f1: 0.5977653631284916\n",
      "precision: 0.7430555555555556\n",
      "recall: 0.5\n",
      "3848 4810\n",
      "The train accuracy score of GBDT is : 0.783784\n",
      "The test accuracy score of GBDT is : 0.744403\n",
      "f1: 0.6267029972752044\n",
      "precision: 0.7516339869281046\n",
      "recall: 0.5373831775700935\n",
      "avg of accuracy of five-fold cross validation is 0.739179\n",
      "avg of f1 of five-fold cross validation is 0.617304\n",
      "avg of precision of five-fold cross validation is 0.745121\n",
      "avg of recall of five-fold cross validation is 0.527103\n"
     ]
    }
   ],
   "source": [
    "num_train = x.shape[0]\n",
    "num_each_part = num_train//5\n",
    "print(\"num of train data is %s and each of part(1/5) is %s \"%(num_train,num_each_part))\n",
    "test_accuracy_list = list()\n",
    "test_f1_list = list()\n",
    "test_precision_list=list()\n",
    "test_recall_list=list()\n",
    "for i in range(5):\n",
    "    print(num_each_part*i,num_each_part*(i+1))\n",
    "    train_x = x_std[num_each_part*i:num_each_part*(i+1)]\n",
    "    train_y = y[num_each_part*i:num_each_part*(i+1)]\n",
    "    gbdt = LogisticRegression()\n",
    "    gbdt.fit(train_x,train_y)\n",
    "    train_score_rbf = gbdt.score(train_x, train_y)\n",
    "    print(\"The train accuracy score of GBDT is : %f\" % train_score_rbf)\n",
    "    test_score_rbf = gbdt.score(test_x_std, test_y)\n",
    "    print(\"The test accuracy score of GBDT is : %f\" % test_score_rbf)\n",
    "    predict_y = gbdt.predict(test_x_std)\n",
    "    prob_y = gbdt.predict_proba(test_x_std)[:,1]\n",
    "    from sklearn.metrics import confusion_matrix,f1_score\n",
    "    f1 = f1_score(test_y, predict_y, average='binary')\n",
    "    print(\"f1:\", f1 )\n",
    "    p = precision_score(test_y, predict_y, average='binary')\n",
    "    print(\"precision:\", p)\n",
    "    r = recall_score(test_y, predict_y,average='binary')\n",
    "    print(\"recall:\", r)\n",
    "\n",
    "    test_accuracy_list.append(test_score_rbf)\n",
    "    test_f1_list.append(f1)\n",
    "    test_precision_list.append(p)\n",
    "    test_recall_list.append(r)\n",
    "print(\"avg of accuracy of five-fold cross validation is %f\"%(np.mean(np.asarray(test_accuracy_list))))\n",
    "print(\"avg of f1 of five-fold cross validation is %f\"%(np.mean(np.asarray(test_f1_list))))\n",
    "print(\"avg of precision of five-fold cross validation is %f\"%(np.mean(np.asarray(test_precision_list))))\n",
    "print(\"avg of recall of five-fold cross validation is %f\"%(np.mean(np.asarray(test_recall_list))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM(rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[:, 1:]  \n",
    "y = data[:, 0].astype(int)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_data[:, 1:]\n",
    "test_y = test_data[:, 0].astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train data is 4814 and each of part(1/5) is 962 \n",
      "0 962\n",
      "The train accuracy score of GBDT is : 0.880457\n",
      "The test accuracy score of GBDT is : 0.722015\n",
      "f1: 0.6590389016018307\n",
      "precision: 0.6457399103139013\n",
      "recall: 0.6728971962616822\n",
      "962 1924\n",
      "The train accuracy score of GBDT is : 0.879418\n",
      "The test accuracy score of GBDT is : 0.722015\n",
      "f1: 0.6392251815980629\n",
      "precision: 0.6633165829145728\n",
      "recall: 0.616822429906542\n",
      "1924 2886\n",
      "The train accuracy score of GBDT is : 0.875260\n",
      "The test accuracy score of GBDT is : 0.718284\n",
      "f1: 0.6447058823529411\n",
      "precision: 0.6492890995260664\n",
      "recall: 0.6401869158878505\n",
      "2886 3848\n",
      "The train accuracy score of GBDT is : 0.866944\n",
      "The test accuracy score of GBDT is : 0.742537\n",
      "f1: 0.5964912280701754\n",
      "precision: 0.796875\n",
      "recall: 0.4766355140186916\n",
      "3848 4810\n",
      "The train accuracy score of GBDT is : 0.887734\n",
      "The test accuracy score of GBDT is : 0.701493\n",
      "f1: 0.6521739130434782\n",
      "precision: 0.6097560975609756\n",
      "recall: 0.7009345794392523\n",
      "avg of accuracy of five-fold cross validation is 0.721269\n",
      "avg of f1 of five-fold cross validation is 0.638327\n",
      "avg of precision of five-fold cross validation is 0.672995\n",
      "avg of recall of five-fold cross validation is 0.621495\n"
     ]
    }
   ],
   "source": [
    "num_train = x.shape[0]\n",
    "num_each_part = num_train//5\n",
    "print(\"num of train data is %s and each of part(1/5) is %s \"%(num_train,num_each_part))\n",
    "test_accuracy_list = list()\n",
    "test_f1_list = list()\n",
    "test_precision_list=list()\n",
    "test_recall_list=list()\n",
    "for i in range(5):\n",
    "    print(num_each_part*i,num_each_part*(i+1))\n",
    "    train_x = x[num_each_part*i:num_each_part*(i+1)]\n",
    "    train_y = y[num_each_part*i:num_each_part*(i+1)]\n",
    "    gbdt = SVC(kernel='rbf',probability=True)\n",
    "    gbdt.fit(train_x,train_y)\n",
    "    train_score_rbf = gbdt.score(train_x, train_y)\n",
    "    print(\"The train accuracy score of GBDT is : %f\" % train_score_rbf)\n",
    "    test_score_rbf = gbdt.score(test_x, test_y)\n",
    "    print(\"The test accuracy score of GBDT is : %f\" % test_score_rbf)\n",
    "    predict_y = gbdt.predict(test_x)\n",
    "    prob_y = gbdt.predict_proba(test_x)[:,1]\n",
    "    from sklearn.metrics import confusion_matrix,f1_score\n",
    "    f1 = f1_score(test_y, predict_y, average='binary')\n",
    "    print(\"f1:\", f1 )\n",
    "    p = precision_score(test_y, predict_y, average='binary')\n",
    "    print(\"precision:\", p)\n",
    "    r = recall_score(test_y, predict_y,average='binary')\n",
    "    print(\"recall:\", r)\n",
    "\n",
    "    test_accuracy_list.append(test_score_rbf)\n",
    "    test_f1_list.append(f1)\n",
    "    test_precision_list.append(p)\n",
    "    test_recall_list.append(r)\n",
    "print(\"avg of accuracy of five-fold cross validation is %f\"%(np.mean(np.asarray(test_accuracy_list))))\n",
    "print(\"avg of f1 of five-fold cross validation is %f\"%(np.mean(np.asarray(test_f1_list))))\n",
    "print(\"avg of precision of five-fold cross validation is %f\"%(np.mean(np.asarray(test_precision_list))))\n",
    "print(\"avg of recall of five-fold cross validation is %f\"%(np.mean(np.asarray(test_recall_list))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM(rbf) + standScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_std = scaler.transform(x)\n",
    "test_x_std = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train data is 4814 and each of part(1/5) is 962 \n",
      "0 962\n",
      "The train accuracy score of GBDT is : 0.757796\n",
      "The test accuracy score of GBDT is : 0.751866\n",
      "f1: 0.6453333333333334\n",
      "precision: 0.7515527950310559\n",
      "recall: 0.5654205607476636\n",
      "962 1924\n",
      "The train accuracy score of GBDT is : 0.785863\n",
      "The test accuracy score of GBDT is : 0.755597\n",
      "f1: 0.6579634464751958\n",
      "precision: 0.7455621301775148\n",
      "recall: 0.5887850467289719\n",
      "1924 2886\n",
      "The train accuracy score of GBDT is : 0.781705\n",
      "The test accuracy score of GBDT is : 0.740672\n",
      "f1: 0.6463104325699746\n",
      "precision: 0.7094972067039106\n",
      "recall: 0.5934579439252337\n",
      "2886 3848\n",
      "The train accuracy score of GBDT is : 0.778586\n",
      "The test accuracy score of GBDT is : 0.744403\n",
      "f1: 0.6422976501305484\n",
      "precision: 0.727810650887574\n",
      "recall: 0.5747663551401869\n",
      "3848 4810\n",
      "The train accuracy score of GBDT is : 0.794179\n",
      "The test accuracy score of GBDT is : 0.751866\n",
      "f1: 0.6545454545454544\n",
      "precision: 0.7368421052631579\n",
      "recall: 0.5887850467289719\n",
      "avg of accuracy of five-fold cross validation is 0.748881\n",
      "avg of f1 of five-fold cross validation is 0.649290\n",
      "avg of precision of five-fold cross validation is 0.734253\n",
      "avg of recall of five-fold cross validation is 0.582243\n"
     ]
    }
   ],
   "source": [
    "num_train = x.shape[0]\n",
    "num_each_part = num_train//5\n",
    "print(\"num of train data is %s and each of part(1/5) is %s \"%(num_train,num_each_part))\n",
    "test_accuracy_list = list()\n",
    "test_f1_list = list()\n",
    "test_precision_list=list()\n",
    "test_recall_list=list()\n",
    "for i in range(5):\n",
    "    print(num_each_part*i,num_each_part*(i+1))\n",
    "    train_x = x_std[num_each_part*i:num_each_part*(i+1)]\n",
    "    train_y = y[num_each_part*i:num_each_part*(i+1)]\n",
    "    gbdt =SVC(kernel='rbf',probability=True)\n",
    "    gbdt.fit(train_x,train_y)\n",
    "    train_score_rbf = gbdt.score(train_x, train_y)\n",
    "    print(\"The train accuracy score of GBDT is : %f\" % train_score_rbf)\n",
    "    test_score_rbf = gbdt.score(test_x_std, test_y)\n",
    "    print(\"The test accuracy score of GBDT is : %f\" % test_score_rbf)\n",
    "    predict_y = gbdt.predict(test_x_std)\n",
    "    prob_y = gbdt.predict_proba(test_x_std)[:,1]\n",
    "    from sklearn.metrics import confusion_matrix,f1_score\n",
    "    f1 = f1_score(test_y, predict_y, average='binary')\n",
    "    print(\"f1:\", f1 )\n",
    "    p = precision_score(test_y, predict_y, average='binary')\n",
    "    print(\"precision:\", p)\n",
    "    r = recall_score(test_y, predict_y,average='binary')\n",
    "    print(\"recall:\", r)\n",
    "\n",
    "    test_accuracy_list.append(test_score_rbf)\n",
    "    test_f1_list.append(f1)\n",
    "    test_precision_list.append(p)\n",
    "    test_recall_list.append(r)\n",
    "print(\"avg of accuracy of five-fold cross validation is %f\"%(np.mean(np.asarray(test_accuracy_list))))\n",
    "print(\"avg of f1 of five-fold cross validation is %f\"%(np.mean(np.asarray(test_f1_list))))\n",
    "print(\"avg of precision of five-fold cross validation is %f\"%(np.mean(np.asarray(test_precision_list))))\n",
    "print(\"avg of recall of five-fold cross validation is %f\"%(np.mean(np.asarray(test_recall_list))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM(linear)\n",
    "without standScaler is impossible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = data[:, 1:] \n",
    "# y = data[:, 0].astype(int)  \n",
    "\n",
    "# test_x = test_data[:, 1:] \n",
    "# test_y = test_data[:, 0].astype(int) \n",
    "\n",
    "# svm = SVC(kernel='linear',probability=True)\n",
    "# svm.fit(x, y)\n",
    "# val_score_rbf = svm.score(x, y)\n",
    "# print(\"The val accuracy score of SVM(linear) is : %f\" % val_score_rbf)\n",
    "# test_score_rbf = svm.score(test_x, test_y)\n",
    "# print(\"The test accuracy score of SVM(linear) is : %f\" % test_score_rbf)\n",
    "# predict_y = svm.predict(test_x)\n",
    "# prob_y = svm.predict_proba(test_x)[:,1]\n",
    "# print(\"f1:\",f1_score(test_y, predict_y, average='binary')  )\n",
    "\n",
    "# fpr, tpr, thresholds = roc_curve(test_y, prob_y,pos_label=1)\n",
    "# plt.close('all')\n",
    "# plt.plot(fpr,tpr)\n",
    "# plt.title(\"ROC\")\n",
    "# plt.show()\n",
    "\n",
    "# roc_auc_score(test_y, prob_y)\n",
    "# print(\"AUC:\",roc_auc_score(test_y, prob_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM(linear) + standScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_std = scaler.transform(x)\n",
    "test_x_std = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train data is 4814 and each of part(1/5) is 962 \n",
      "0 962\n",
      "The train accuracy score of GBDT is : 0.769231\n",
      "The test accuracy score of GBDT is : 0.738806\n",
      "f1: 0.6067415730337078\n",
      "precision: 0.7605633802816901\n",
      "recall: 0.5046728971962616\n",
      "962 1924\n",
      "The train accuracy score of GBDT is : 0.790021\n",
      "The test accuracy score of GBDT is : 0.729478\n",
      "f1: 0.5938375350140056\n",
      "precision: 0.7412587412587412\n",
      "recall: 0.4953271028037383\n",
      "1924 2886\n",
      "The train accuracy score of GBDT is : 0.784823\n",
      "The test accuracy score of GBDT is : 0.723881\n",
      "f1: 0.5911602209944752\n",
      "precision: 0.722972972972973\n",
      "recall: 0.5\n",
      "2886 3848\n",
      "The train accuracy score of GBDT is : 0.770270\n",
      "The test accuracy score of GBDT is : 0.722015\n",
      "f1: 0.565597667638484\n",
      "precision: 0.751937984496124\n",
      "recall: 0.4532710280373832\n",
      "3848 4810\n",
      "The train accuracy score of GBDT is : 0.798337\n",
      "The test accuracy score of GBDT is : 0.738806\n",
      "f1: 0.6089385474860336\n",
      "precision: 0.7569444444444444\n",
      "recall: 0.5093457943925234\n",
      "avg of accuracy of five-fold cross validation is 0.730597\n",
      "avg of f1 of five-fold cross validation is 0.593255\n",
      "avg of precision of five-fold cross validation is 0.746736\n",
      "avg of recall of five-fold cross validation is 0.492523\n"
     ]
    }
   ],
   "source": [
    "num_train = x.shape[0]\n",
    "num_each_part = num_train//5\n",
    "print(\"num of train data is %s and each of part(1/5) is %s \"%(num_train,num_each_part))\n",
    "test_accuracy_list = list()\n",
    "test_f1_list = list()\n",
    "test_precision_list=list()\n",
    "test_recall_list=list()\n",
    "for i in range(5):\n",
    "    print(num_each_part*i,num_each_part*(i+1))\n",
    "    train_x = x_std[num_each_part*i:num_each_part*(i+1)]\n",
    "    train_y = y[num_each_part*i:num_each_part*(i+1)]\n",
    "    gbdt =SVC(kernel='linear',probability=True)\n",
    "    gbdt.fit(train_x,train_y)\n",
    "    train_score_rbf = gbdt.score(train_x, train_y)\n",
    "    print(\"The train accuracy score of GBDT is : %f\" % train_score_rbf)\n",
    "    test_score_rbf = gbdt.score(test_x_std, test_y)\n",
    "    print(\"The test accuracy score of GBDT is : %f\" % test_score_rbf)\n",
    "    predict_y = gbdt.predict(test_x_std)\n",
    "    prob_y = gbdt.predict_proba(test_x_std)[:,1]\n",
    "    from sklearn.metrics import confusion_matrix,f1_score\n",
    "    f1 = f1_score(test_y, predict_y, average='binary')\n",
    "    print(\"f1:\", f1 )\n",
    "    p = precision_score(test_y, predict_y, average='binary')\n",
    "    print(\"precision:\", p)\n",
    "    r = recall_score(test_y, predict_y,average='binary')\n",
    "    print(\"recall:\", r)\n",
    "\n",
    "    test_accuracy_list.append(test_score_rbf)\n",
    "    test_f1_list.append(f1)\n",
    "    test_precision_list.append(p)\n",
    "    test_recall_list.append(r)\n",
    "print(\"avg of accuracy of five-fold cross validation is %f\"%(np.mean(np.asarray(test_accuracy_list))))\n",
    "print(\"avg of f1 of five-fold cross validation is %f\"%(np.mean(np.asarray(test_f1_list))))\n",
    "print(\"avg of precision of five-fold cross validation is %f\"%(np.mean(np.asarray(test_precision_list))))\n",
    "print(\"avg of recall of five-fold cross validation is %f\"%(np.mean(np.asarray(test_recall_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
