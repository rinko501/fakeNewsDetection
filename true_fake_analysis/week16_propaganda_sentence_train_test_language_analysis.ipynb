{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linliu/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding:utf-8 -*-\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import csv\n",
    "from scipy.stats import chi2_contingency\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,f1_score,roc_auc_score,roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(dict_names):\n",
    "    \n",
    "    print(\"current dict: \",dict_names)\n",
    "\n",
    "                \n",
    "    def load_propaganda_task2():\n",
    "        '''\n",
    "        output:[[sentence, label]]\n",
    "        '''\n",
    "        global_sentence_label = list()\n",
    "\n",
    "        tesk_2_3_path = '../other_dict/tasks-2-3/train/'\n",
    "        target_data_2_dirs = os.listdir(tesk_2_3_path)\n",
    "        article_name_set = set()\n",
    "        for file_name in target_data_2_dirs:\n",
    "            article_name_set.add(file_name.split(\".\")[0])\n",
    "        for index in list(article_name_set):\n",
    "            file_name = index + '.txt'\n",
    "            text_name = tesk_2_3_path + file_name\n",
    "            try:\n",
    "                text = open(text_name, encoding='utf-8', mode='r')\n",
    "            except:\n",
    "                print('No such file or directory: ', text_name)\n",
    "                continue\n",
    "            label_name = tesk_2_3_path + index + '.task2.labels'\n",
    "            try:\n",
    "                label = open(label_name, encoding='utf-8', mode='r')\n",
    "            except:\n",
    "                print('No such file or directory: ', label_name)\n",
    "                continue\n",
    "            #print('text_name:',text_name[:2])\n",
    "            text = text.readlines()\n",
    "            #print('text:',text[:2])\n",
    "            sentence_list = []\n",
    "            for sentence in text:\n",
    "                sentence_list.append(sentence)\n",
    "            label = label.readlines()\n",
    "            #print('label:',label[:2])\n",
    "            label_list = []\n",
    "            for line in label:\n",
    "                label_list.append(line)\n",
    "            assert len(label_list)==len(sentence_list),\"text name %s, len of text %d, \\\n",
    "                    len of label %d\"%(text_name, len(sentence_list), len(label_list))\n",
    "            for index,sentence in enumerate(sentence_list):\n",
    "                if \"\\tnon-propaganda\" in label_list[index] and sentence.strip()!=\"\":\n",
    "                    global_sentence_label.append([sentence,0])\n",
    "                elif \"\\tpropaganda\" in label_list[index] and sentence.strip()!=\"\":\n",
    "                    global_sentence_label.append([sentence,1])\n",
    "                else:\n",
    "                    continue\n",
    "        return global_sentence_label\n",
    "    # load data\n",
    "    \n",
    "    global_sentence_label = load_propaganda_task2()\n",
    "    #print('global_sentence_label:',global_sentence_label[:2])\n",
    "    np.random.shuffle(global_sentence_label)\n",
    "    # partition to positive/negative\n",
    "    global_sentence_label_positive = [pair for pair in global_sentence_label if pair[1]==1]\n",
    "    global_sentence_label_negative = [pair for pair in global_sentence_label if pair[1]==0][:3938]\n",
    "#     print(\"num of sentence is %d\"%(len(global_sentence_label)))\n",
    "#     print(\"num of pos sentence is %d\"%(len(global_sentence_label_positive)))\n",
    "#     print(\"num of neg sentence is %d\"%(len(global_sentence_label_negative)))\n",
    "    # shuffle and partition to train/validation/test\n",
    "    #np.random.shuffle(global_sentence_label_negative)\n",
    "    #np.random.shuffle(global_sentence_label_positive)\n",
    "\n",
    "    train_dataset = global_sentence_label_negative[:int(len(global_sentence_label_negative)*0.9)]\n",
    "    train_dataset.extend(global_sentence_label_positive[:int(len(global_sentence_label_positive)*0.9)])\n",
    "\n",
    "    validation_dataset = global_sentence_label_negative[int(len(global_sentence_label_negative)*0.9):]\n",
    "    validation_dataset.extend(global_sentence_label_positive[int(len(global_sentence_label_negative)*0.9):])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    global_test_sentence_label = list()\n",
    "    sentence_test_list = []\n",
    "    label_test_list = []\n",
    "    with open('../other_dict/new_propaganda_test/task2test_rs.csv','r') as csvfile_test_test:\n",
    "        reader_test = csv.reader(csvfile_test_test)\n",
    "        for i,rows in enumerate(reader_test):\n",
    "            num_test=1\n",
    "            if i in range(1,4032):\n",
    "                #if i ==1:\n",
    "                i==num_test\n",
    "                row_test = rows\n",
    "                #print('row_test:',row_test)\n",
    "                #column = [row[1] for row in reader]\n",
    "                text_name = row_test[:2]\n",
    "                text_test = row_test[3]\n",
    "                label =row_test[2]\n",
    "                if label==\"non-propaganda\":\n",
    "                    global_test_sentence_label.append([text_test,0])\n",
    "                    #print('global_sentence_label_non:',global_sentence_label)\n",
    "                elif label==\"propaganda\":\n",
    "                    global_test_sentence_label.append([text_test,1])\n",
    "                    #print('global_sentence_label:',global_sentence_label)\n",
    "                else:\n",
    "                    continue\n",
    "     #print('global_test_sentence_label:',global_test_sentence_label[:2])\n",
    "\n",
    "    # partition to positive/negative\n",
    "    global_test_sentence_label_positive = [pair for pair in global_test_sentence_label if pair[1]==1]\n",
    "    global_test_sentence_label_negative = [pair for pair in global_test_sentence_label if pair[1]==0]\n",
    "    #print(\"num of sentence is %d\"%(len(global_test_sentence_label)))\n",
    "    #print(\"num of pos sentence is %d\"%(len(global_test_sentence_label_positive)))\n",
    "    #print(\"num of neg sentence is %d\"%(len(global_test_sentence_label_negative)))\n",
    "    # shuffle and partition to train/validation/test\n",
    "    \n",
    "    \n",
    "    \n",
    "    test_dataset = global_test_sentence_label_negative[:]\n",
    "    test_dataset.extend(global_test_sentence_label_positive[:])\n",
    "    #     print(\"num of train %d\"%(len(train_dataset)))\n",
    "    #     print(\"num of validation %d\"%(len(validation_dataset)))\n",
    "    #     print(\"num of test %d\"%(len(test_dataset)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def load_dict(dict_path):\n",
    "        word_set = set()\n",
    "        dict_text = open(dict_path, encoding='utf-8', mode='r')\n",
    "        for line in dict_text:\n",
    "            if line.strip()!=\"\":\n",
    "                word =line.split(\",\")[0]\n",
    "                word_set.add(word)\n",
    "        return word_set\n",
    "    def word_num_in_dict(sentence, word_set):\n",
    "        try:\n",
    "            word_list = sentence.strip().split(\" \")\n",
    "        except:\n",
    "            print(sentence)\n",
    "        word_num = 0\n",
    "        for word in word_list:\n",
    "            if word in word_set:\n",
    "                word_num += 1\n",
    "        return word_num\n",
    "    def build_feature_matrix_and_label(dataset,dict_names,dict_path):\n",
    "        num_sample = len(dataset)\n",
    "        num_feature = len(dict_names)\n",
    "        feature_matrix = np.zeros((num_sample, num_feature))\n",
    "        label = np.zeros((num_sample,))\n",
    "        for i in range(num_sample):\n",
    "            for j in range(num_feature):\n",
    "                if 'propaganda' in dict_names[j]:\n",
    "                    dict_path='./result_fake_true_week5/'\n",
    "                else:\n",
    "                    dict_path=\"./result_fake_true_after_reduce_stopwords/\"\n",
    "                feature_matrix[i,j] = word_num_in_dict(dataset[i][0], load_dict(dict_path + dict_names[j] + \"_words.csv\"))\n",
    "            label[i] = dataset[i][1]\n",
    "        return feature_matrix,label\n",
    "    def build_feature_matrix_new_one_dict(dataset,dict_name,dict_path):\n",
    "        if 'propaganda' in dict_name:\n",
    "            dict_path='./result_fake_true_week5/'\n",
    "        else:\n",
    "            dict_path=\"./result_fake_true_after_reduce_stopwords\"\n",
    "        word_list = list(load_dict(dict_path+dict_name+ \"_words.csv\"))\n",
    "        num_sample = len(dataset)\n",
    "        num_feature = len(word_list)\n",
    "        feature_matrix = np.zeros((num_sample, num_feature))\n",
    "        for i in range(len(dataset)):\n",
    "            for j,word in enumerate(word_list):\n",
    "                if word in dataset[i][0]:\n",
    "                    feature_matrix[i][j]=1\n",
    "        return(feature_matrix)\n",
    "    #dict_names = ['fake_persuasive','fake_sentiment','fake_subjectivity','fake_technical','fake_all',\n",
    "    #              'true_persuasive','true_sentiment','true_subjectivity','true_technical','true_all']\n",
    "    #dict_names = ['fake_persuasive','fake_sentiment','fake_subjectivity','fake_technical',\n",
    "    #              'true_persuasive','true_sentiment','true_subjectivity','true_technical']\n",
    "    dict_path = \"./result_fake_true_after_reduce_stopwords\"\n",
    "    train_feature_matrix, train_label = build_feature_matrix_and_label(train_dataset, dict_names, dict_path)\n",
    "    validation_feature_matrix, validation_label = build_feature_matrix_and_label(validation_dataset, dict_names, dict_path)\n",
    "    test_feature_matrix, test_label = build_feature_matrix_and_label(test_dataset, dict_names, dict_path)\n",
    "    # one-hot feature\n",
    "    for dict_name in dict_names:\n",
    "        train_feature_matrix=np.hstack((build_feature_matrix_new_one_dict(train_dataset,dict_names[0],dict_path),train_feature_matrix))\n",
    "        validation_feature_matrix=np.hstack((build_feature_matrix_new_one_dict(validation_dataset,dict_names[0],dict_path),validation_feature_matrix))\n",
    "        test_feature_matrix=np.hstack((build_feature_matrix_new_one_dict(test_dataset,dict_names[0],dict_path),test_feature_matrix))\n",
    "\n",
    "    #gbdt train again and predict\n",
    "    train_feature_matrix = np.vstack((validation_feature_matrix,train_feature_matrix))\n",
    "    \n",
    "    \n",
    "    train_label = np.concatenate((validation_label,train_label))\n",
    "#     print(train_feature_matrix.shape, train_label.shape)\n",
    "    gbdt = GradientBoostingClassifier(max_depth=4,\n",
    "                                      random_state=0,\n",
    "                                      min_samples_split=5,\n",
    "                                      learning_rate=0.01,\n",
    "                                      n_estimators=30,\n",
    "                                      subsample=0.8)\n",
    "    rf = gbdt.fit(train_feature_matrix, train_label)\n",
    "    val_score_rbf = gbdt.score(train_feature_matrix, train_label)\n",
    "#     print(\"The train accuracy score of rf is : %f\" % val_score_rbf)\n",
    "    #test_score_rbf = gbdt.score(test_feature_matrix, test_label)\n",
    "    \n",
    "    #print(\"Final: The test accuracy score of rf is : %f\" % test_score_rbf )\n",
    "    #predict_label = gbdt.predict(test_feature_matrix)\n",
    "    \n",
    "    prediction=gbdt.predict(test_feature_matrix)\n",
    "    #test_score=f1_score(prediction,test_label)\n",
    "    #print('f1:',f1_score(prediction,test_label))\n",
    "    from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "    f1 = f1_score(prediction,test_label, average='binary')\n",
    "    print(\"f1:\", f1 )\n",
    "    p = precision_score(prediction,test_label, average='binary')\n",
    "    print(\"precision:\", p)\n",
    "    r = recall_score(prediction,test_label,average='binary')\n",
    "    print(\"recall:\", r)\n",
    "    # confusion matrix \n",
    "    def plot_confusion_matrix(cm, title):\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]   \n",
    "        plt.imshow(cm) \n",
    "        print(cm)\n",
    "        plt.title(title)   \n",
    "        plt.colorbar()\n",
    "        plt.ylabel('True label')    \n",
    "        plt.xlabel('Predicted label')\n",
    "#     cm = confusion_matrix(test_label, predict_label)\n",
    "#     print(\"confusion matrix is \", cm)\n",
    "    #plot_confusion_matrix(cm, \"RF Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current dict:  ['fake_persuasive', 'true_persuasive']\n",
      "f1: 0.37396883593033914\n",
      "precision: 0.3295638126009693\n",
      "recall: 0.4322033898305085\n",
      "current dict:  ['fake_sentiment', 'true_sentiment']\n",
      "f1: 0.3527013251783894\n",
      "precision: 0.27948303715670436\n",
      "recall: 0.47790055248618785\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_sentiment', 'true_sentiment']\n",
      "f1: 0.3672897196261682\n",
      "precision: 0.3174474959612278\n",
      "recall: 0.4356984478935698\n",
      "current dict:  ['fake_subjectivity', 'true_subjectivity']\n",
      "f1: 0.4382790510655408\n",
      "precision: 0.44022617124394187\n",
      "recall: 0.4363490792634107\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_subjectivity', 'true_subjectivity']\n",
      "f1: 0.44488501189532126\n",
      "precision: 0.4531502423263328\n",
      "recall: 0.4369158878504673\n",
      "current dict:  ['fake_sentiment', 'true_sentiment', 'fake_subjectivity', 'true_subjectivity']\n",
      "f1: 0.40523465703971123\n",
      "precision: 0.36268174474959614\n",
      "recall: 0.4591002044989775\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_sentiment', 'true_sentiment', 'fake_subjectivity', 'true_subjectivity']\n",
      "f1: 0.43654001616814875\n",
      "precision: 0.43618739903069464\n",
      "recall: 0.4368932038834951\n",
      "current dict:  ['fake_technical', 'true_technical']\n",
      "f1: 0.3052284503061705\n",
      "precision: 0.2617124394184168\n",
      "recall: 0.36610169491525424\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_technical', 'true_technical']\n",
      "f1: 0.37248771773112993\n",
      "precision: 0.3368336025848142\n",
      "recall: 0.4165834165834166\n",
      "current dict:  ['fake_sentiment', 'true_sentiment', 'fake_technical', 'true_technical']\n",
      "f1: 0.35427491733585265\n",
      "precision: 0.30290791599353795\n",
      "recall: 0.42662116040955633\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_sentiment', 'true_sentiment', 'fake_technical', 'true_technical']\n",
      "f1: 0.3855098389982111\n",
      "precision: 0.3481421647819063\n",
      "recall: 0.4318637274549098\n",
      "current dict:  ['fake_subjectivity', 'true_subjectivity', 'fake_technical', 'true_technical']\n",
      "f1: 0.43168957154405824\n",
      "precision: 0.43134087237479807\n",
      "recall: 0.4320388349514563\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_subjectivity', 'true_subjectivity', 'fake_technical', 'true_technical']\n",
      "f1: 0.44079999999999997\n",
      "precision: 0.44507269789983844\n",
      "recall: 0.436608557844691\n",
      "current dict:  ['fake_sentiment', 'true_sentiment', 'fake_subjectivity', 'true_subjectivity', 'fake_technical', 'true_technical']\n",
      "f1: 0.4416932907348242\n",
      "precision: 0.4466882067851373\n",
      "recall: 0.4368088467614534\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_sentiment', 'true_sentiment', 'fake_subjectivity', 'true_subjectivity', 'fake_technical', 'true_technical']\n",
      "f1: 0.44258373205741625\n",
      "precision: 0.4483037156704362\n",
      "recall: 0.43700787401574803\n",
      "current dict:  ['fake_all', 'true_all']\n",
      "f1: 0.4649842271293375\n",
      "precision: 0.5953150242326333\n",
      "recall: 0.38146997929606624\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_all', 'true_all']\n",
      "f1: 0.4448183041722745\n",
      "precision: 0.5339256865912763\n",
      "recall: 0.381199538638985\n",
      "current dict:  ['fake_sentiment', 'true_sentiment', 'fake_all', 'true_all']\n",
      "f1: 0.4545162327225972\n",
      "precision: 0.5710823909531503\n",
      "recall: 0.3774693005872931\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_sentiment', 'true_sentiment', 'fake_all', 'true_all']\n",
      "f1: 0.45205037132709075\n",
      "precision: 0.5654281098546042\n",
      "recall: 0.37654653039268426\n",
      "current dict:  ['fake_subjectivity', 'true_subjectivity', 'fake_all', 'true_all']\n",
      "f1: 0.4605137963843958\n",
      "precision: 0.5864297253634895\n",
      "recall: 0.37911227154046995\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_subjectivity', 'true_subjectivity', 'fake_all', 'true_all']\n",
      "f1: 0.4544859201047806\n",
      "precision: 0.5605815831987075\n",
      "recall: 0.38215859030837\n",
      "current dict:  ['fake_sentiment', 'true_sentiment', 'fake_subjectivity', 'true_subjectivity', 'fake_all', 'true_all']\n",
      "f1: 0.4590476190476191\n",
      "precision: 0.5840064620355412\n",
      "recall: 0.37813807531380755\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_sentiment', 'true_sentiment', 'fake_subjectivity', 'true_subjectivity', 'fake_all', 'true_all']\n",
      "f1: 0.4599416153097632\n",
      "precision: 0.5726978998384491\n",
      "recall: 0.3842818428184282\n",
      "current dict:  ['fake_technical', 'true_technical', 'fake_all', 'true_all']\n",
      "f1: 0.42953885843276357\n",
      "precision: 0.5379644588045234\n",
      "recall: 0.357487922705314\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_technical', 'true_technical', 'fake_all', 'true_all']\n",
      "f1: 0.4460622104566512\n",
      "precision: 0.5444264943457189\n",
      "recall: 0.3778026905829596\n",
      "current dict:  ['fake_sentiment', 'true_sentiment', 'fake_technical', 'true_technical', 'fake_all', 'true_all']\n",
      "f1: 0.458034321372855\n",
      "precision: 0.592891760904685\n",
      "recall: 0.373157092018302\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_sentiment', 'true_sentiment', 'fake_technical', 'true_technical', 'fake_all', 'true_all']\n",
      "f1: 0.46212361331220286\n",
      "precision: 0.5888529886914378\n",
      "recall: 0.38028169014084506\n",
      "current dict:  ['fake_subjectivity', 'true_subjectivity', 'fake_technical', 'true_technical', 'fake_all', 'true_all']\n",
      "f1: 0.45343609505459215\n",
      "precision: 0.5702746365105008\n",
      "recall: 0.3763326226012793\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_subjectivity', 'true_subjectivity', 'fake_technical', 'true_technical', 'fake_all', 'true_all']\n",
      "f1: 0.4515917295700689\n",
      "precision: 0.555735056542811\n",
      "recall: 0.38032061912658927\n",
      "current dict:  ['fake_sentiment', 'true_sentiment', 'fake_subjectivity', 'true_subjectivity', 'fake_technical', 'true_technical', 'fake_all', 'true_all']\n",
      "f1: 0.4602218700475436\n",
      "precision: 0.5864297253634895\n",
      "recall: 0.37871674491392804\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_sentiment', 'true_sentiment', 'fake_subjectivity', 'true_subjectivity', 'fake_technical', 'true_technical', 'fake_all', 'true_all']\n",
      "f1: 0.4600253807106599\n",
      "precision: 0.5856219709208401\n",
      "recall: 0.3787878787878788\n",
      "current dict:  ['fake_subjectivity', 'true_subjectivity']\n",
      "f1: 0.43134087237479807\n",
      "precision: 0.43134087237479807\n",
      "recall: 0.43134087237479807\n",
      "[[], ['persuasive'], ['sentiment'], ['persuasive', 'sentiment'], ['subjectivity'], ['persuasive', 'subjectivity'], ['sentiment', 'subjectivity'], ['persuasive', 'sentiment', 'subjectivity'], ['technical'], ['persuasive', 'technical'], ['sentiment', 'technical'], ['persuasive', 'sentiment', 'technical'], ['subjectivity', 'technical'], ['persuasive', 'subjectivity', 'technical'], ['sentiment', 'subjectivity', 'technical'], ['persuasive', 'sentiment', 'subjectivity', 'technical'], ['all'], ['persuasive', 'all'], ['sentiment', 'all'], ['persuasive', 'sentiment', 'all'], ['subjectivity', 'all'], ['persuasive', 'subjectivity', 'all'], ['sentiment', 'subjectivity', 'all'], ['persuasive', 'sentiment', 'subjectivity', 'all'], ['technical', 'all'], ['persuasive', 'technical', 'all'], ['sentiment', 'technical', 'all'], ['persuasive', 'sentiment', 'technical', 'all'], ['subjectivity', 'technical', 'all'], ['persuasive', 'subjectivity', 'technical', 'all'], ['sentiment', 'subjectivity', 'technical', 'all'], ['persuasive', 'sentiment', 'subjectivity', 'technical', 'all']]\n"
     ]
    }
   ],
   "source": [
    "all_dict = ['persuasive','sentiment','subjectivity','technical','all']\n",
    "dict_num = len(all_dict)\n",
    "f1score_list=[]\n",
    "sub_list_all = []  \n",
    "for i in range(1 << dict_num):  \n",
    "    combo_list = [] \n",
    "    for j in range(dict_num):\n",
    "        if i & (1 << j): \n",
    "            combo_list.append(all_dict[j]) \n",
    "    sub_list_all.append(combo_list)\n",
    "#print(sub_list_all)\n",
    "for ele in sub_list_all[1:]:\n",
    "    dict_names = list()\n",
    "    for i in ele:\n",
    "        dict_names.extend([\"fake_\"+i, \"true_\"+i])\n",
    "    feature_importance(dict_names)\n",
    "feature_importance(['fake_subjectivity', 'true_subjectivity'])\n",
    "\n",
    "\n",
    "print(sub_list_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current dict:  ['fake_persuasive', 'true_persuasive']\n",
      "f1: 0.43225572103160187\n",
      "current dict:  ['fake_sentiment', 'true_sentiment']\n",
      "f1: 0.3664566165777994\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_sentiment', 'true_sentiment']\n",
      "f1: 0.4444444444444444\n",
      "current dict:  ['fake_nrc_emotion', 'true_nrc_emotion']\n",
      "f1: 0.35525024533856725\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_nrc_emotion', 'true_nrc_emotion']\n",
      "f1: 0.4570823030731191\n",
      "current dict:  ['fake_sentiment', 'true_sentiment', 'fake_nrc_emotion', 'true_nrc_emotion']\n",
      "f1: 0.41388066017774017\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_sentiment', 'true_sentiment', 'fake_nrc_emotion', 'true_nrc_emotion']\n",
      "f1: 0.4131374243733794\n",
      "current dict:  ['fake_subjectivity', 'true_subjectivity']\n",
      "f1: 0.4510427712972782\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_subjectivity', 'true_subjectivity']\n",
      "f1: 0.4713328369322412\n",
      "current dict:  ['fake_sentiment', 'true_sentiment', 'fake_subjectivity', 'true_subjectivity']\n",
      "f1: 0.4509321139641224\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_sentiment', 'true_sentiment', 'fake_subjectivity', 'true_subjectivity']\n",
      "f1: 0.46768771012327226\n",
      "current dict:  ['fake_nrc_emotion', 'true_nrc_emotion', 'fake_subjectivity', 'true_subjectivity']\n",
      "f1: 0.4432809773123909\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_nrc_emotion', 'true_nrc_emotion', 'fake_subjectivity', 'true_subjectivity']\n",
      "f1: 0.45425644648534086\n",
      "current dict:  ['fake_sentiment', 'true_sentiment', 'fake_nrc_emotion', 'true_nrc_emotion', 'fake_subjectivity', 'true_subjectivity']\n",
      "f1: 0.4547044421126268\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_sentiment', 'true_sentiment', 'fake_nrc_emotion', 'true_nrc_emotion', 'fake_subjectivity', 'true_subjectivity']\n",
      "f1: 0.4417536534446764\n",
      "current dict:  ['fake_technical', 'true_technical']\n",
      "f1: 0.2958637469586375\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_technical', 'true_technical']\n",
      "f1: 0.4497126436781609\n",
      "current dict:  ['fake_sentiment', 'true_sentiment', 'fake_technical', 'true_technical']\n",
      "f1: 0.3803571428571429\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_sentiment', 'true_sentiment', 'fake_technical', 'true_technical']\n",
      "f1: 0.427940586109996\n",
      "current dict:  ['fake_nrc_emotion', 'true_nrc_emotion', 'fake_technical', 'true_technical']\n",
      "f1: 0.37707120465741156\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_nrc_emotion', 'true_nrc_emotion', 'fake_technical', 'true_technical']\n",
      "f1: 0.4523979957050823\n",
      "current dict:  ['fake_sentiment', 'true_sentiment', 'fake_nrc_emotion', 'true_nrc_emotion', 'fake_technical', 'true_technical']\n",
      "f1: 0.4240755310778914\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_sentiment', 'true_sentiment', 'fake_nrc_emotion', 'true_nrc_emotion', 'fake_technical', 'true_technical']\n",
      "f1: 0.4166309472781826\n",
      "current dict:  ['fake_subjectivity', 'true_subjectivity', 'fake_technical', 'true_technical']\n",
      "f1: 0.4653061224489796\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_subjectivity', 'true_subjectivity', 'fake_technical', 'true_technical']\n",
      "f1: 0.45277679518924663\n",
      "current dict:  ['fake_sentiment', 'true_sentiment', 'fake_subjectivity', 'true_subjectivity', 'fake_technical', 'true_technical']\n",
      "f1: 0.4085491163173038\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_sentiment', 'true_sentiment', 'fake_subjectivity', 'true_subjectivity', 'fake_technical', 'true_technical']\n",
      "f1: 0.4206805125939019\n",
      "current dict:  ['fake_nrc_emotion', 'true_nrc_emotion', 'fake_subjectivity', 'true_subjectivity', 'fake_technical', 'true_technical']\n",
      "f1: 0.44116613979627683\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_nrc_emotion', 'true_nrc_emotion', 'fake_subjectivity', 'true_subjectivity', 'fake_technical', 'true_technical']\n",
      "f1: 0.45114006514657984\n",
      "current dict:  ['fake_sentiment', 'true_sentiment', 'fake_nrc_emotion', 'true_nrc_emotion', 'fake_subjectivity', 'true_subjectivity', 'fake_technical', 'true_technical']\n",
      "f1: 0.4500176616036736\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_sentiment', 'true_sentiment', 'fake_nrc_emotion', 'true_nrc_emotion', 'fake_subjectivity', 'true_subjectivity', 'fake_technical', 'true_technical']\n",
      "f1: 0.4510218463706836\n",
      "current dict:  ['fake_all', 'true_all']\n",
      "f1: 0.47973778307508935\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_all', 'true_all']\n",
      "f1: 0.4729186010523058\n",
      "current dict:  ['fake_sentiment', 'true_sentiment', 'fake_all', 'true_all']\n",
      "f1: 0.4793041391721655\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_sentiment', 'true_sentiment', 'fake_all', 'true_all']\n",
      "f1: 0.46373850868232885\n",
      "current dict:  ['fake_nrc_emotion', 'true_nrc_emotion', 'fake_all', 'true_all']\n",
      "f1: 0.4806480648064807\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_nrc_emotion', 'true_nrc_emotion', 'fake_all', 'true_all']\n",
      "f1: 0.48066135222911127\n",
      "current dict:  ['fake_sentiment', 'true_sentiment', 'fake_nrc_emotion', 'true_nrc_emotion', 'fake_all', 'true_all']\n",
      "f1: 0.48019064641048553\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_sentiment', 'true_sentiment', 'fake_nrc_emotion', 'true_nrc_emotion', 'fake_all', 'true_all']\n",
      "f1: 0.4832254267216009\n",
      "current dict:  ['fake_subjectivity', 'true_subjectivity', 'fake_all', 'true_all']\n",
      "f1: 0.47245564892623715\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_subjectivity', 'true_subjectivity', 'fake_all', 'true_all']\n",
      "f1: 0.4847226342331652\n",
      "current dict:  ['fake_sentiment', 'true_sentiment', 'fake_subjectivity', 'true_subjectivity', 'fake_all', 'true_all']\n",
      "f1: 0.4819349059420722\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_sentiment', 'true_sentiment', 'fake_subjectivity', 'true_subjectivity', 'fake_all', 'true_all']\n",
      "f1: 0.47549794498893455\n",
      "current dict:  ['fake_nrc_emotion', 'true_nrc_emotion', 'fake_subjectivity', 'true_subjectivity', 'fake_all', 'true_all']\n",
      "f1: 0.4843184559710494\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_nrc_emotion', 'true_nrc_emotion', 'fake_subjectivity', 'true_subjectivity', 'fake_all', 'true_all']\n",
      "f1: 0.4797859690844233\n",
      "current dict:  ['fake_sentiment', 'true_sentiment', 'fake_nrc_emotion', 'true_nrc_emotion', 'fake_subjectivity', 'true_subjectivity', 'fake_all', 'true_all']\n",
      "f1: 0.47879973907371165\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_sentiment', 'true_sentiment', 'fake_nrc_emotion', 'true_nrc_emotion', 'fake_subjectivity', 'true_subjectivity', 'fake_all', 'true_all']\n",
      "f1: 0.48723340342445187\n",
      "current dict:  ['fake_technical', 'true_technical', 'fake_all', 'true_all']\n",
      "f1: 0.4630940343781597\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_technical', 'true_technical', 'fake_all', 'true_all']\n",
      "f1: 0.47357032457496134\n",
      "current dict:  ['fake_sentiment', 'true_sentiment', 'fake_technical', 'true_technical', 'fake_all', 'true_all']\n",
      "f1: 0.4569420035149384\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_sentiment', 'true_sentiment', 'fake_technical', 'true_technical', 'fake_all', 'true_all']\n",
      "f1: 0.47264337508239945\n",
      "current dict:  ['fake_nrc_emotion', 'true_nrc_emotion', 'fake_technical', 'true_technical', 'fake_all', 'true_all']\n",
      "f1: 0.48373743347131876\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_nrc_emotion', 'true_nrc_emotion', 'fake_technical', 'true_technical', 'fake_all', 'true_all']\n",
      "f1: 0.4795918367346938\n",
      "current dict:  ['fake_sentiment', 'true_sentiment', 'fake_nrc_emotion', 'true_nrc_emotion', 'fake_technical', 'true_technical', 'fake_all', 'true_all']\n",
      "f1: 0.46791171477079796\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_sentiment', 'true_sentiment', 'fake_nrc_emotion', 'true_nrc_emotion', 'fake_technical', 'true_technical', 'fake_all', 'true_all']\n",
      "f1: 0.480569563927618\n",
      "current dict:  ['fake_subjectivity', 'true_subjectivity', 'fake_technical', 'true_technical', 'fake_all', 'true_all']\n",
      "f1: 0.4796625489605303\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_subjectivity', 'true_subjectivity', 'fake_technical', 'true_technical', 'fake_all', 'true_all']\n",
      "f1: 0.4792655903767014\n",
      "current dict:  ['fake_sentiment', 'true_sentiment', 'fake_subjectivity', 'true_subjectivity', 'fake_technical', 'true_technical', 'fake_all', 'true_all']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.4855007473841555\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_sentiment', 'true_sentiment', 'fake_subjectivity', 'true_subjectivity', 'fake_technical', 'true_technical', 'fake_all', 'true_all']\n",
      "f1: 0.48588885656095426\n",
      "current dict:  ['fake_nrc_emotion', 'true_nrc_emotion', 'fake_subjectivity', 'true_subjectivity', 'fake_technical', 'true_technical', 'fake_all', 'true_all']\n",
      "f1: 0.4835230677052127\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_nrc_emotion', 'true_nrc_emotion', 'fake_subjectivity', 'true_subjectivity', 'fake_technical', 'true_technical', 'fake_all', 'true_all']\n",
      "f1: 0.4819860732667272\n",
      "current dict:  ['fake_sentiment', 'true_sentiment', 'fake_nrc_emotion', 'true_nrc_emotion', 'fake_subjectivity', 'true_subjectivity', 'fake_technical', 'true_technical', 'fake_all', 'true_all']\n",
      "f1: 0.46126760563380287\n",
      "current dict:  ['fake_persuasive', 'true_persuasive', 'fake_sentiment', 'true_sentiment', 'fake_nrc_emotion', 'true_nrc_emotion', 'fake_subjectivity', 'true_subjectivity', 'fake_technical', 'true_technical', 'fake_all', 'true_all']\n",
      "f1: 0.4821103699211643\n",
      "current dict:  ['fake_subjectivity', 'true_subjectivity']\n",
      "f1: 0.44863135442587987\n",
      "[[], ['persuasive'], ['sentiment'], ['persuasive', 'sentiment'], ['nrc_emotion'], ['persuasive', 'nrc_emotion'], ['sentiment', 'nrc_emotion'], ['persuasive', 'sentiment', 'nrc_emotion'], ['subjectivity'], ['persuasive', 'subjectivity'], ['sentiment', 'subjectivity'], ['persuasive', 'sentiment', 'subjectivity'], ['nrc_emotion', 'subjectivity'], ['persuasive', 'nrc_emotion', 'subjectivity'], ['sentiment', 'nrc_emotion', 'subjectivity'], ['persuasive', 'sentiment', 'nrc_emotion', 'subjectivity'], ['technical'], ['persuasive', 'technical'], ['sentiment', 'technical'], ['persuasive', 'sentiment', 'technical'], ['nrc_emotion', 'technical'], ['persuasive', 'nrc_emotion', 'technical'], ['sentiment', 'nrc_emotion', 'technical'], ['persuasive', 'sentiment', 'nrc_emotion', 'technical'], ['subjectivity', 'technical'], ['persuasive', 'subjectivity', 'technical'], ['sentiment', 'subjectivity', 'technical'], ['persuasive', 'sentiment', 'subjectivity', 'technical'], ['nrc_emotion', 'subjectivity', 'technical'], ['persuasive', 'nrc_emotion', 'subjectivity', 'technical'], ['sentiment', 'nrc_emotion', 'subjectivity', 'technical'], ['persuasive', 'sentiment', 'nrc_emotion', 'subjectivity', 'technical'], ['all'], ['persuasive', 'all'], ['sentiment', 'all'], ['persuasive', 'sentiment', 'all'], ['nrc_emotion', 'all'], ['persuasive', 'nrc_emotion', 'all'], ['sentiment', 'nrc_emotion', 'all'], ['persuasive', 'sentiment', 'nrc_emotion', 'all'], ['subjectivity', 'all'], ['persuasive', 'subjectivity', 'all'], ['sentiment', 'subjectivity', 'all'], ['persuasive', 'sentiment', 'subjectivity', 'all'], ['nrc_emotion', 'subjectivity', 'all'], ['persuasive', 'nrc_emotion', 'subjectivity', 'all'], ['sentiment', 'nrc_emotion', 'subjectivity', 'all'], ['persuasive', 'sentiment', 'nrc_emotion', 'subjectivity', 'all'], ['technical', 'all'], ['persuasive', 'technical', 'all'], ['sentiment', 'technical', 'all'], ['persuasive', 'sentiment', 'technical', 'all'], ['nrc_emotion', 'technical', 'all'], ['persuasive', 'nrc_emotion', 'technical', 'all'], ['sentiment', 'nrc_emotion', 'technical', 'all'], ['persuasive', 'sentiment', 'nrc_emotion', 'technical', 'all'], ['subjectivity', 'technical', 'all'], ['persuasive', 'subjectivity', 'technical', 'all'], ['sentiment', 'subjectivity', 'technical', 'all'], ['persuasive', 'sentiment', 'subjectivity', 'technical', 'all'], ['nrc_emotion', 'subjectivity', 'technical', 'all'], ['persuasive', 'nrc_emotion', 'subjectivity', 'technical', 'all'], ['sentiment', 'nrc_emotion', 'subjectivity', 'technical', 'all'], ['persuasive', 'sentiment', 'nrc_emotion', 'subjectivity', 'technical', 'all']]\n",
      "+--------------------------------------------------------------------------------+------+\n",
      "|                                  current dict                                  |  f1  |\n",
      "+--------------------------------------------------------------------------------+------+\n",
      "|                                 ['persuasive']                                 | None |\n",
      "|                                 ['sentiment']                                  | None |\n",
      "|                          ['persuasive', 'sentiment']                           | None |\n",
      "|                                ['nrc_emotion']                                 | None |\n",
      "|                         ['persuasive', 'nrc_emotion']                          | None |\n",
      "|                          ['sentiment', 'nrc_emotion']                          | None |\n",
      "|                   ['persuasive', 'sentiment', 'nrc_emotion']                   | None |\n",
      "|                                ['subjectivity']                                | None |\n",
      "|                         ['persuasive', 'subjectivity']                         | None |\n",
      "|                         ['sentiment', 'subjectivity']                          | None |\n",
      "|                  ['persuasive', 'sentiment', 'subjectivity']                   | None |\n",
      "|                        ['nrc_emotion', 'subjectivity']                         | None |\n",
      "|                 ['persuasive', 'nrc_emotion', 'subjectivity']                  | None |\n",
      "|                  ['sentiment', 'nrc_emotion', 'subjectivity']                  | None |\n",
      "|           ['persuasive', 'sentiment', 'nrc_emotion', 'subjectivity']           | None |\n",
      "|                                 ['technical']                                  | None |\n",
      "|                          ['persuasive', 'technical']                           | None |\n",
      "|                           ['sentiment', 'technical']                           | None |\n",
      "|                    ['persuasive', 'sentiment', 'technical']                    | None |\n",
      "|                          ['nrc_emotion', 'technical']                          | None |\n",
      "|                   ['persuasive', 'nrc_emotion', 'technical']                   | None |\n",
      "|                   ['sentiment', 'nrc_emotion', 'technical']                    | None |\n",
      "|            ['persuasive', 'sentiment', 'nrc_emotion', 'technical']             | None |\n",
      "|                         ['subjectivity', 'technical']                          | None |\n",
      "|                  ['persuasive', 'subjectivity', 'technical']                   | None |\n",
      "|                   ['sentiment', 'subjectivity', 'technical']                   | None |\n",
      "|            ['persuasive', 'sentiment', 'subjectivity', 'technical']            | None |\n",
      "|                  ['nrc_emotion', 'subjectivity', 'technical']                  | None |\n",
      "|           ['persuasive', 'nrc_emotion', 'subjectivity', 'technical']           | None |\n",
      "|           ['sentiment', 'nrc_emotion', 'subjectivity', 'technical']            | None |\n",
      "|    ['persuasive', 'sentiment', 'nrc_emotion', 'subjectivity', 'technical']     | None |\n",
      "|                                    ['all']                                     | None |\n",
      "|                             ['persuasive', 'all']                              | None |\n",
      "|                              ['sentiment', 'all']                              | None |\n",
      "|                       ['persuasive', 'sentiment', 'all']                       | None |\n",
      "|                             ['nrc_emotion', 'all']                             | None |\n",
      "|                      ['persuasive', 'nrc_emotion', 'all']                      | None |\n",
      "|                      ['sentiment', 'nrc_emotion', 'all']                       | None |\n",
      "|               ['persuasive', 'sentiment', 'nrc_emotion', 'all']                | None |\n",
      "|                            ['subjectivity', 'all']                             | None |\n",
      "|                     ['persuasive', 'subjectivity', 'all']                      | None |\n",
      "|                      ['sentiment', 'subjectivity', 'all']                      | None |\n",
      "|               ['persuasive', 'sentiment', 'subjectivity', 'all']               | None |\n",
      "|                     ['nrc_emotion', 'subjectivity', 'all']                     | None |\n",
      "|              ['persuasive', 'nrc_emotion', 'subjectivity', 'all']              | None |\n",
      "|              ['sentiment', 'nrc_emotion', 'subjectivity', 'all']               | None |\n",
      "|       ['persuasive', 'sentiment', 'nrc_emotion', 'subjectivity', 'all']        | None |\n",
      "|                              ['technical', 'all']                              | None |\n",
      "|                       ['persuasive', 'technical', 'all']                       | None |\n",
      "|                       ['sentiment', 'technical', 'all']                        | None |\n",
      "|                ['persuasive', 'sentiment', 'technical', 'all']                 | None |\n",
      "|                      ['nrc_emotion', 'technical', 'all']                       | None |\n",
      "|               ['persuasive', 'nrc_emotion', 'technical', 'all']                | None |\n",
      "|                ['sentiment', 'nrc_emotion', 'technical', 'all']                | None |\n",
      "|         ['persuasive', 'sentiment', 'nrc_emotion', 'technical', 'all']         | None |\n",
      "|                      ['subjectivity', 'technical', 'all']                      | None |\n",
      "|               ['persuasive', 'subjectivity', 'technical', 'all']               | None |\n",
      "|               ['sentiment', 'subjectivity', 'technical', 'all']                | None |\n",
      "|        ['persuasive', 'sentiment', 'subjectivity', 'technical', 'all']         | None |\n",
      "|              ['nrc_emotion', 'subjectivity', 'technical', 'all']               | None |\n",
      "|       ['persuasive', 'nrc_emotion', 'subjectivity', 'technical', 'all']        | None |\n",
      "|        ['sentiment', 'nrc_emotion', 'subjectivity', 'technical', 'all']        | None |\n",
      "| ['persuasive', 'sentiment', 'nrc_emotion', 'subjectivity', 'technical', 'all'] | None |\n",
      "+--------------------------------------------------------------------------------+------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "x= PrettyTable([\"current dict\", \"f1\"])\n",
    "f1score_list=[]\n",
    "all_dict = ['persuasive','sentiment','nrc_emotion','subjectivity','technical','all']\n",
    "dict_num = len(all_dict)\n",
    "sub_list_all = []  \n",
    "for i in range(1 << dict_num):  \n",
    "    combo_list = [] \n",
    "    for j in range(dict_num):\n",
    "        if i & (1 << j): \n",
    "            combo_list.append(all_dict[j]) \n",
    "    sub_list_all.append(combo_list)\n",
    "#print(sub_list_all)\n",
    "for ele in sub_list_all[1:]:\n",
    "    dict_names = list()\n",
    "    for i in ele:\n",
    "        dict_names.extend([\"fake_\"+i, \"true_\"+i])\n",
    "    score=feature_importance(dict_names)\n",
    "    x.add_row([ele,score])\n",
    "                   \n",
    "feature_importance(['fake_subjectivity', 'true_subjectivity'])\n",
    "print(sub_list_all)\n",
    "print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
